{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc24c217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bsq_aws/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c4c26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV\n",
    "df = pd.read_csv('../data/5b_stage0_refined.csv')\n",
    "dataset = Dataset.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c9b546e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bsq_aws/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/bsq_aws/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocessing\n",
    "model_name = \"microsoft/deberta-v3-small\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14125d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 12064/12064 [00:00<00:00, 18519.57 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess(examples):\n",
    "    # Tokenize\n",
    "    tokens = tokenizer(\n",
    "        examples[\"NL_Query\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    # Attach labels\n",
    "    tokens[\"labels\"] = examples[\"Label\"]    # <— make sure it’s 'labels'\n",
    "    return tokens\n",
    "tokenized_datasets = dataset.map(preprocess, batched=True)\n",
    "\n",
    "# Train/test split\n",
    "split = tokenized_datasets.train_test_split(test_size=0.2)\n",
    "train_dataset = split[\"train\"]\n",
    "eval_dataset = split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78c965cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    from sklearn.metrics import f1_score, accuracy_score\n",
    "    labels = pred.label_ids\n",
    "    preds  = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\":       f1_score(labels, preds, average=\"macro\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b381b03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/906 [00:00<?, ?it/s]/opt/miniconda3/envs/bsq_aws/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 33%|███▎      | 302/906 [03:45<18:51,  1.87s/it]\n",
      " 33%|███▎      | 302/906 [04:03<18:51,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.011976677924394608, 'eval_accuracy': 0.9979278905926233, 'eval_f1': 0.9940236434489308, 'eval_runtime': 18.0698, 'eval_samples_per_second': 133.538, 'eval_steps_per_second': 4.206, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bsq_aws/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 55%|█████▌    | 500/906 [06:32<05:05,  1.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0612, 'grad_norm': 0.0019127613632008433, 'learning_rate': 8.962472406181016e-05, 'epoch': 1.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 604/906 [07:52<03:53,  1.29it/s]\n",
      " 67%|██████▋   | 604/906 [08:11<03:53,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9139500838937238e-05, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 19.2028, 'eval_samples_per_second': 125.659, 'eval_steps_per_second': 3.958, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bsq_aws/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "100%|██████████| 906/906 [12:45<00:00,  1.15it/s]\n",
      "100%|██████████| 906/906 [13:08<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9513141523930244e-05, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 22.9107, 'eval_samples_per_second': 105.322, 'eval_steps_per_second': 3.317, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 906/906 [13:13<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 793.2481, 'train_samples_per_second': 36.499, 'train_steps_per_second': 1.142, 'train_loss': 0.03379114517822829, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=906, training_loss=0.03379114517822829, metrics={'train_runtime': 793.2481, 'train_samples_per_second': 36.499, 'train_steps_per_second': 1.142, 'total_flos': 958900501490688.0, 'train_loss': 0.03379114517822829, 'epoch': 3.0})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "\n",
    "# Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"out\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",            # ← match eval\n",
    "    load_best_model_at_end=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "144f0fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did revenue drop in Q2 2024? → [{'label': 'LABEL_2', 'score': 0.9999641180038452}]\n",
      "Show me the EBITDA over the last 4 quarters. → [{'label': 'LABEL_0', 'score': 0.9999899864196777}]\n",
      "When was the EBITDA higher - this year or last → [{'label': 'LABEL_1', 'score': 0.9999946355819702}]\n",
      "Can you detect anomalies? → [{'label': 'LABEL_2', 'score': 0.9999668598175049}]\n",
      "Is a Price-to-Book ratio of 1.8 considered healthy → [{'label': 'LABEL_3', 'score': 0.9998692274093628}]\n",
      "Does the Gross Profit margin look abnormal this quarter? → [{'label': 'LABEL_2', 'score': 0.9999681711196899}]\n",
      "Please provide the value of Current Assets last year. → [{'label': 'LABEL_0', 'score': 0.9999895095825195}]\n",
      "PAT → [{'label': 'LABEL_0', 'score': 0.9999803304672241}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "clf = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=trainer.model,        # or your checkpoint path\n",
    "    tokenizer=tokenizer,\n",
    "    device=-1                    # or -1 for CPU\n",
    ")\n",
    "\n",
    "samples = [\n",
    "    \"Why did revenue drop in Q2 2024?\",\n",
    "    \"Show me the EBITDA over the last 4 quarters.\",\n",
    "    \"When was the EBITDA higher - this year or last\",\n",
    "    \"Can you detect anomalies?\",\n",
    "    \"Is a Price-to-Book ratio of 1.8 considered healthy\",\n",
    "    \"Does the Gross Profit margin look abnormal this quarter?\",\n",
    "    \"Please provide the value of Current Assets last year.\",\n",
    "    \"PAT\"\n",
    "]\n",
    "\n",
    "for q in samples:\n",
    "    print(q, \"→\", clf(q))\n",
    "\n",
    "## 0 -> Query, 1 -> Comparison, 2 -> Anomaly Detection, 3 -> Others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867421e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Can you tell me the Revenue for Q3 2024?' → Predicted: 0, True: 0\n",
      "'Revenue' → Predicted: 0, True: 0\n",
      "'EBIDTA' → Predicted: 0, True: 0\n",
      "'Ebidta - how has it changed this year vs last' → Predicted: 1, True: 1\n",
      "'When was the EBITDA higher - this year or last' → Predicted: 1, True: 1\n",
      "'I would like to receive the Net Profit (PAT) figure for 2023.' → Predicted: 0, True: 0\n",
      "'What was the EBITDA amount in Q1 2024?' → Predicted: 0, True: 0\n",
      "'Give me the Cost of Goods Sold (COGS) for the previous quarter.' → Predicted: 0, True: 0\n",
      "'Compare Operating Profit (EBIT) in Q2 2023 vs Q2 2024.' → Predicted: 1, True: 1\n",
      "'How does ROE for 2022 and 2023 fare against each other?' → Predicted: 1, True: 1\n",
      "'Is the Current Ratio higher in Q4 2023 or Q1 2024?' → Predicted: 1, True: 1\n",
      "'Please contrast Free Cash Flow across the last three years.' → Predicted: 1, True: 1\n",
      "'Which is better: Debt-to-Equity Ratio or Interest Coverage Ratio?' → Predicted: 1, True: 1\n",
      "'Is there any anomaly in Receivables Turnover for Q3 2023?' → Predicted: 2, True: 2\n",
      "'Why did the Working Capital suddenly spike in Q1 2024?' → Predicted: 2, True: 2\n",
      "'Does the Gross Profit margin look abnormal this quarter?' → Predicted: 2, True: 2\n",
      "'There was a sharp drop in Inventories in 2023—what caused it?' → Predicted: 2, True: 2\n",
      "'Detect any irregularity in Operating Cash Flow over the past four quarters.' → Predicted: 2, True: 2\n",
      "'What is the trend in EPS over the past five years?' → Predicted: 3, True: 3\n",
      "'Forecast the Revenue for Q1 2025 based on historical data.' → Predicted: 2, True: 3\n",
      "'Is a Price-to-Book ratio of 1.8 considered healthy?' → Predicted: 3, True: 3\n",
      "'Why did Gross Profit fall despite higher Revenue?' → Predicted: 3, True: 3\n",
      "'Should we be concerned about the low Quick Ratio this quarter?' → Predicted: 0, True: 3\n",
      "\n",
      "============================================================\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Querying (0)       0.86      1.00      0.92         6\n",
      "Comparison (1)       1.00      1.00      1.00         7\n",
      "   Anomaly (2)       0.83      1.00      0.91         5\n",
      "     Other (3)       1.00      0.60      0.75         5\n",
      "\n",
      "      accuracy                           0.91        23\n",
      "     macro avg       0.92      0.90      0.90        23\n",
      "  weighted avg       0.93      0.91      0.91        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 1) Define your test cases (query, true_label)\n",
    "test_cases = [\n",
    "    (\"Can you tell me the Revenue for Q3 2024?\", 0),\n",
    "    (\"Revenue\", 0),\n",
    "    (\"EBIDTA\", 0),\n",
    "    (\"Ebidta - how has it changed this year vs last\", 1),\n",
    "    (\"When was the EBITDA higher - this year or last\", 1),\n",
    "    (\"I would like to receive the Net Profit (PAT) figure for 2023.\", 0),\n",
    "    (\"What was the EBITDA amount in Q1 2024?\", 0),\n",
    "    (\"Give me the Cost of Goods Sold (COGS) for the previous quarter.\", 0),\n",
    "    (\"Compare Operating Profit (EBIT) in Q2 2023 vs Q2 2024.\", 1),\n",
    "    (\"How does ROE for 2022 and 2023 fare against each other?\", 1),\n",
    "    (\"Is the Current Ratio higher in Q4 2023 or Q1 2024?\", 1),\n",
    "    (\"Please contrast Free Cash Flow across the last three years.\", 1),\n",
    "    (\"Which is better: Debt-to-Equity Ratio or Interest Coverage Ratio?\", 1),\n",
    "    (\"Is there any anomaly in Receivables Turnover for Q3 2023?\", 2),\n",
    "    (\"Why did the Working Capital suddenly spike in Q1 2024?\", 2),\n",
    "    (\"Does the Gross Profit margin look abnormal this quarter?\", 2),\n",
    "    (\"There was a sharp drop in Inventories in 2023—what caused it?\", 2),\n",
    "    (\"Detect any irregularity in Operating Cash Flow over the past four quarters.\", 2),\n",
    "    (\"What is the trend in EPS over the past five years?\", 3),\n",
    "    (\"Forecast the Revenue for Q1 2025 based on historical data.\", 3),\n",
    "    (\"Is a Price-to-Book ratio of 1.8 considered healthy?\", 3),\n",
    "    (\"Why did Gross Profit fall despite higher Revenue?\", 3),\n",
    "    (\"Should we be concerned about the low Quick Ratio this quarter?\", 3),\n",
    "]\n",
    "\n",
    "# 2) Run the classifier and collect preds/trues\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "for query, true_label in test_cases:\n",
    "    # pipeline returns a list of dicts: [{\"label\":\"LABEL_X\",\"score\":...}]\n",
    "    out = clf(query, top_k=None)[0]\n",
    "    pred_label = int(out[\"label\"].split(\"_\")[-1])\n",
    "    preds.append(pred_label)\n",
    "    trues.append(true_label)\n",
    "    print(f\"{query!r} → Predicted: {pred_label}, True: {true_label}\")\n",
    "\n",
    "# 3) Print class‐wise precision/recall/F1\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(classification_report(\n",
    "    trues,\n",
    "    preds,\n",
    "    target_names=[\n",
    "        \"Querying (0)\",\n",
    "        \"Comparison (1)\",\n",
    "        \"Anomaly (2)\",\n",
    "        \"Other (3)\"\n",
    "    ]\n",
    "))\n",
    "\n",
    "## 0 -> Query, 1 -> Comparison, 2 -> Anomaly Detection, 3 -> Others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d22a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0 -> Query, 1 -> Comparison, 2 -> Anomaly Detection, 3 -> Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d61b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Save with Trainer API\n",
    "trainer.save_model(\"../results/15jul_stage0/trained_model\")  \n",
    "# This does the same as model.save_pretrained and also writes config.json.\n",
    "\n",
    "# 2. Save the tokenizer\n",
    "tokenizer.save_pretrained(\"../results/15jul_stage0/trained_tokeniser\")\n",
    "\n",
    "# 3. (Optional) Save training arguments / state\n",
    "trainer.state.save_to_json(\"../results/15jul_stage0/trained_args.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557fbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsq_aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
